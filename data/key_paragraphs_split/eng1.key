Fifty runs were applied with different random seeds for generating the random variables, each containing 5000 iterations. Computations were performed in Matlab on a computer running Macintosh OS, two 2.93 GHz 6
-
Core Intel processors, 64 GB Ram, and ATI Radeon HD 5870 graphics card. Figures 2 to 8 show the experimental results of applying all the algorithms to seven Benchmark functions with different values of parameters. As can be seen, the MSCA for most parameters has better convergence to the minimum of the Benchmark functions than the other optimization algorithms. This proves that MSCA is able to avoid becoming trapped in local optima in the problem space and to achieve the global minimum. In the MSCA, the cells having higher comparative power than the other cells are very good for global optimization, and normal self
-
renewal process for best selected cells is very efficient for local optimization. Therefore we obtain better performance using MSCA in optimizing unimodal and multimodal functions. For different dimensions (10, 20, 30 and 40) the mean and standard derivation (SD) function values of the best solution found by the algorithms (GA, PSO, ACO, ABC, SCA and MSCA) are shown in Tables A.1 to A.7 in the Appendix.
