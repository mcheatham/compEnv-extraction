The fact that the current algorithm is capable of producing intelligibility by HI listeners that exceeds that achieved when their NH counterparts are presented with noisy stimuli is quite encouraging and suggests that the current algorithm may potentially be simplified in various ways (e.g., without using two future frames described in Sec. IIC) to reduce processing demand, while still providing adequate levels of benefit. This may be important, given an eventual goal of implementation into hearing technology, including hearing aids and cochlear implants. We stress that this goal is long term and that the current algorithm is far from ready to implement. On the other hand, the current algorithm possesses attributes suggesting that its eventual implementation may be possible. First, the monaural nature of the algorithm provides inherent convenience in implementation relative to microphone-array techniques. Second, the classification-based framework shifts much of the workload to a training stage. During the operational (test) stage, the algorithm involves only feature extraction and binary labeling using trained classifiers, both of which could be performed efficiently. As an indication of processing time, the current algorithm takes approximately 123 ms (107 for feature extraction and 16 for DNN classification) per frequency channel to separate a 3-s noisy utterance using a single Intel 2.8 GHz Xeon processor. We should mention that no attempt was made to optimize processing speed as this was not an objective of the current study; e.g., a significant increase in speed could be achieved by replacing the current MATLAB implementation of feature extraction with a C implementation.
